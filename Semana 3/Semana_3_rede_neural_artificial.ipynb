{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Semana_3_rede_neural_artificial.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPFyRyfWJ2+Ob7RgkygfgOb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leovaldesz/Atividades-Aprendizagem-de-m-quina/blob/master/Semana%203/Semana_3_rede_neural_artificial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7gNdgDDIdv1",
        "colab_type": "text"
      },
      "source": [
        "## Classificação de casos de insuficiência cardíaca"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oOzJBjFI9o2",
        "colab_type": "text"
      },
      "source": [
        "* Dataset com atributos de pacientes que tiveram insuficiência cardíaca e um atributo classificador para se eles morreram ou não.\n",
        "*   `https://www.kaggle.com/andrewmvd/heart-failure-clinical-data`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kRHilM6JLnX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bda6149a-4173-4322-8377-fa44c48d12b4"
      },
      "source": [
        "#Montando o ambiente\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ9TwCjJKuE0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "51f9fab7-44ae-4272-f072-43f511f2626b"
      },
      "source": [
        "#ler CSV\n",
        "dados = pd.read_csv('/content/drive/My Drive/Colab Notebooks/datasets/heart_failure_clinical_records_dataset.csv')\n",
        "dados.head()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>anaemia</th>\n",
              "      <th>creatinine_phosphokinase</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>ejection_fraction</th>\n",
              "      <th>high_blood_pressure</th>\n",
              "      <th>platelets</th>\n",
              "      <th>serum_creatinine</th>\n",
              "      <th>serum_sodium</th>\n",
              "      <th>sex</th>\n",
              "      <th>smoking</th>\n",
              "      <th>time</th>\n",
              "      <th>DEATH_EVENT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75.0</td>\n",
              "      <td>0</td>\n",
              "      <td>582</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>265000.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>130</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55.0</td>\n",
              "      <td>0</td>\n",
              "      <td>7861</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>263358.03</td>\n",
              "      <td>1.1</td>\n",
              "      <td>136</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65.0</td>\n",
              "      <td>0</td>\n",
              "      <td>146</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>162000.00</td>\n",
              "      <td>1.3</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50.0</td>\n",
              "      <td>1</td>\n",
              "      <td>111</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>210000.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>137</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>65.0</td>\n",
              "      <td>1</td>\n",
              "      <td>160</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>327000.00</td>\n",
              "      <td>2.7</td>\n",
              "      <td>116</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    age  anaemia  creatinine_phosphokinase  ...  smoking  time  DEATH_EVENT\n",
              "0  75.0        0                       582  ...        0     4            1\n",
              "1  55.0        0                      7861  ...        0     6            1\n",
              "2  65.0        0                       146  ...        1     7            1\n",
              "3  50.0        1                       111  ...        0     7            1\n",
              "4  65.0        1                       160  ...        0     8            1\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDZz_vsiLQyn",
        "colab_type": "text"
      },
      "source": [
        "## 1. Limpeza e organização dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reSDIT7wMKYE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "a595a967-a6fd-4eeb-f5ec-c759652e12ef"
      },
      "source": [
        "#Removendo NaN\n",
        "dados.dropna()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>anaemia</th>\n",
              "      <th>creatinine_phosphokinase</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>ejection_fraction</th>\n",
              "      <th>high_blood_pressure</th>\n",
              "      <th>platelets</th>\n",
              "      <th>serum_creatinine</th>\n",
              "      <th>serum_sodium</th>\n",
              "      <th>sex</th>\n",
              "      <th>smoking</th>\n",
              "      <th>time</th>\n",
              "      <th>DEATH_EVENT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75.0</td>\n",
              "      <td>0</td>\n",
              "      <td>582</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>265000.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>130</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55.0</td>\n",
              "      <td>0</td>\n",
              "      <td>7861</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>263358.03</td>\n",
              "      <td>1.1</td>\n",
              "      <td>136</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65.0</td>\n",
              "      <td>0</td>\n",
              "      <td>146</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>162000.00</td>\n",
              "      <td>1.3</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50.0</td>\n",
              "      <td>1</td>\n",
              "      <td>111</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>210000.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>137</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>65.0</td>\n",
              "      <td>1</td>\n",
              "      <td>160</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>327000.00</td>\n",
              "      <td>2.7</td>\n",
              "      <td>116</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294</th>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>155000.00</td>\n",
              "      <td>1.1</td>\n",
              "      <td>143</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>270</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>55.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1820</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>270000.00</td>\n",
              "      <td>1.2</td>\n",
              "      <td>139</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>271</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>45.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2060</td>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>742000.00</td>\n",
              "      <td>0.8</td>\n",
              "      <td>138</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>278</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>45.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2413</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>140000.00</td>\n",
              "      <td>1.4</td>\n",
              "      <td>140</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>280</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>50.0</td>\n",
              "      <td>0</td>\n",
              "      <td>196</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>395000.00</td>\n",
              "      <td>1.6</td>\n",
              "      <td>136</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>285</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>299 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age  anaemia  creatinine_phosphokinase  ...  smoking  time  DEATH_EVENT\n",
              "0    75.0        0                       582  ...        0     4            1\n",
              "1    55.0        0                      7861  ...        0     6            1\n",
              "2    65.0        0                       146  ...        1     7            1\n",
              "3    50.0        1                       111  ...        0     7            1\n",
              "4    65.0        1                       160  ...        0     8            1\n",
              "..    ...      ...                       ...  ...      ...   ...          ...\n",
              "294  62.0        0                        61  ...        1   270            0\n",
              "295  55.0        0                      1820  ...        0   271            0\n",
              "296  45.0        0                      2060  ...        0   278            0\n",
              "297  45.0        0                      2413  ...        1   280            0\n",
              "298  50.0        0                       196  ...        1   285            0\n",
              "\n",
              "[299 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeBZgDQ8MUIF",
        "colab_type": "text"
      },
      "source": [
        "## 2. Re-escala dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oa4Ut7vzMa23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Utilizando o máximo e mínimo\n",
        "dados = (dados - dados.min())/(dados.max() - dados.min())"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beAsgCO_Mr87",
        "colab_type": "text"
      },
      "source": [
        "## 3. Organizando dados para modelagem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr4hi-fxM0Jv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "1dd7a764-9b3e-4cb1-8056-ed5b4369e6df"
      },
      "source": [
        "#Dividindo em atributos descritores\n",
        "X = dados.iloc[:,:len(dados.columns) - 1]\n",
        "X.head()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>anaemia</th>\n",
              "      <th>creatinine_phosphokinase</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>ejection_fraction</th>\n",
              "      <th>high_blood_pressure</th>\n",
              "      <th>platelets</th>\n",
              "      <th>serum_creatinine</th>\n",
              "      <th>serum_sodium</th>\n",
              "      <th>sex</th>\n",
              "      <th>smoking</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.071319</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.290823</td>\n",
              "      <td>0.157303</td>\n",
              "      <td>0.485714</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.288833</td>\n",
              "      <td>0.067416</td>\n",
              "      <td>0.657143</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.015693</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.165960</td>\n",
              "      <td>0.089888</td>\n",
              "      <td>0.457143</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.010676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.181818</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.011227</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.224148</td>\n",
              "      <td>0.157303</td>\n",
              "      <td>0.685714</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.454545</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.017479</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.365984</td>\n",
              "      <td>0.247191</td>\n",
              "      <td>0.085714</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.014235</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        age  anaemia  creatinine_phosphokinase  ...  sex  smoking      time\n",
              "0  0.636364      0.0                  0.071319  ...  1.0      0.0  0.000000\n",
              "1  0.272727      0.0                  1.000000  ...  1.0      0.0  0.007117\n",
              "2  0.454545      0.0                  0.015693  ...  1.0      1.0  0.010676\n",
              "3  0.181818      1.0                  0.011227  ...  1.0      0.0  0.010676\n",
              "4  0.454545      1.0                  0.017479  ...  0.0      0.0  0.014235\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl9lhYnpN-aA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "f83e5efe-27f8-41d5-be4c-293d2544a560"
      },
      "source": [
        "#Dividindo os atributos de classe\n",
        "y = dados.DEATH_EVENT\n",
        "y.head()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1.0\n",
              "1    1.0\n",
              "2    1.0\n",
              "3    1.0\n",
              "4    1.0\n",
              "Name: DEATH_EVENT, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enwViEEOOfgt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "13feee21-8bb7-496d-be6f-4d5aa31a9409"
      },
      "source": [
        "#Dividindo em dados de treino e teste\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2)\n",
        "X_train.head()\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>anaemia</th>\n",
              "      <th>creatinine_phosphokinase</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>ejection_fraction</th>\n",
              "      <th>high_blood_pressure</th>\n",
              "      <th>platelets</th>\n",
              "      <th>serum_creatinine</th>\n",
              "      <th>serum_sodium</th>\n",
              "      <th>sex</th>\n",
              "      <th>smoking</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.011355</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.393939</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.207177</td>\n",
              "      <td>0.056180</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.071174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038658</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.325979</td>\n",
              "      <td>0.134831</td>\n",
              "      <td>0.742857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.768683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.071319</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.288833</td>\n",
              "      <td>0.149438</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.690391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>290</th>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.075529</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.621212</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.238696</td>\n",
              "      <td>0.033708</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.900356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>0.545455</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.005869</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.395078</td>\n",
              "      <td>0.056180</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.142349</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          age  anaemia  creatinine_phosphokinase  ...  sex  smoking      time\n",
              "26   1.000000      1.0                  0.011355  ...  0.0      0.0  0.071174\n",
              "256  0.454545      0.0                  0.038658  ...  0.0      0.0  0.768683\n",
              "220  0.600000      0.0                  0.071319  ...  1.0      0.0  0.690391\n",
              "290  0.090909      0.0                  0.075529  ...  0.0      0.0  0.900356\n",
              "53   0.545455      1.0                  0.005869  ...  0.0      0.0  0.142349\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAT8QzyvPGfW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "5f60e04e-3017-499c-f1da-a98c79cead80"
      },
      "source": [
        "y_train.head()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26     1.0\n",
              "256    0.0\n",
              "220    1.0\n",
              "290    0.0\n",
              "53     1.0\n",
              "Name: DEATH_EVENT, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dsq_mOMMPOPI",
        "colab_type": "text"
      },
      "source": [
        "## 4. Definindo o algoritmo de aprendizagem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6bu4rDBPSzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Qq8su9tPaK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classificador = MLPClassifier(hidden_layer_sizes=(100), activation = 'logistic', max_iter = 1000)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-Rpr2dYPr_A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "35a64dc4-688e-4e14-9cea-78836b35552a"
      },
      "source": [
        "classificador.fit(X_train, y_train)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
              "              beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=100, learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=1000,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca_ZntboQBpA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "520ab360-cc10-4133-a3e8-1273c370825e"
      },
      "source": [
        "classificacao = classificador.predict(X_test)\n",
        "classificacao"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
              "       1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fruc_ph3QUUY",
        "colab_type": "text"
      },
      "source": [
        "## 5. Avaliação do classificador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9fY_thSQiq6",
        "colab_type": "text"
      },
      "source": [
        "#### Acurácia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksKhvCzcQlUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xi7Co-9QtPo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39b968e0-8a44-44be-e148-265ba7f72476"
      },
      "source": [
        "acuracia = accuracy_score(y_test, classificacao)\n",
        "round(acuracia, 3)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.867"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ye5LVl2_ajT0",
        "colab_type": "text"
      },
      "source": [
        "A acurácia mostra a taxa de acertos do classificador, que no caso foi de 86%, esta taxa é alta mas como o domínio do problema trata da saúde de pessoas, seria idal uma acurácia maior. Pórem esta taxa de acerto é medida a partir dos dados separados para teste que pode ter problemas prejudicando ou ajudando nessa taxa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rN9JkfF4RAM4",
        "colab_type": "text"
      },
      "source": [
        "#### Precisão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-BML9cFRG1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import precision_score"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_xSuDn8RMfz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e49dabd6-fe44-4986-ef7f-2cec0100734f"
      },
      "source": [
        "precisao = precision_score(y_test, classificacao)\n",
        "round(precisao, 3)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.786"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQeoBgYCbz8D",
        "colab_type": "text"
      },
      "source": [
        "Esta medida mostra a taxa de positivos que realmente foram classificadas como positivos, e apesar de está proximo do 100% essa taxa é baixa, pois estamos falando de pessoas que tem mais chances de vir a falecer e o módulo classificador diz que ela não estão em perigo, então para o problema a precisão foi baixa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uihZfrmSRXIW",
        "colab_type": "text"
      },
      "source": [
        "#### Recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7nOej7dRbc_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c91e4360-c60f-4e03-adbe-096297afd277"
      },
      "source": [
        "from sklearn.metrics import recall_score\n",
        "recall = recall_score(y_test,classificacao)\n",
        "round(recall,3)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.688"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxPou7eDcgZT",
        "colab_type": "text"
      },
      "source": [
        "Este item mede a taxa de instâncias positivas classificadas corretamente. Esta taxa é muito baixa, nem chega nos 80%, mostrando que o classificador não é muito confiável."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32pFoYyIRoOj",
        "colab_type": "text"
      },
      "source": [
        "#### F1 - score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mu8ekeXmRuo5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9a2d7c7-bf8f-467b-b54a-e0559f6e09aa"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1 = f1_score(y_test,classificacao)\n",
        "round(f1,3)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.733"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgXKVKsGdE3Q",
        "colab_type": "text"
      },
      "source": [
        "O F1-score traz um balanço entre a precisão e o recall. Apesar do resultado ser melhor que o recall, só mostra que o classifcador não está performando tão bem em relação a identificar positivos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7-QiiujR4lL",
        "colab_type": "text"
      },
      "source": [
        "#### Curva ROC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1__vjGUR7E_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "6b875ec8-43df-4d7d-9afe-fbb8152c7de9"
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "fpr, tpr, _ = roc_curve(y_test, classificacao)\n",
        "\n",
        "plt.plot(fpr, tpr, marker = '.')\n",
        "plt.title('Curva ROC')\n",
        "plt.xlabel('Taxa de falsos positivos')\n",
        "plt.ylabel('Taxa de verdadeiros positivos')\n",
        "plt.show()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_IRo9sudkvg",
        "colab_type": "text"
      },
      "source": [
        "Com a plotagem da curva ROC podemos ver que a taxa de verdadeiros positivos não estça tão alta, provavelmente em algum lugar entre 0.6 e 0.8 e como foi visto nas medidas anteriores é próximo de 0.7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUBWNk-GSpAh",
        "colab_type": "text"
      },
      "source": [
        "#### Área sob a curva (Area under de curve - AUC)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1vEpV_8SuU6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "86724823-9e55-499b-c873-cf9821f46cbf"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "auc = roc_auc_score(y_test, classificacao)\n",
        "round(auc,3)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBphoOacd4mu",
        "colab_type": "text"
      },
      "source": [
        "A interpretação númerica da curva ROC mostra que o resultado é 0.825"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcYaaf8ceHmh",
        "colab_type": "text"
      },
      "source": [
        "#### Validação cruzada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHTlMoyoePo6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "73362c5d-9aac-4bcd-945c-d0ccd0b632fe"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "#definindo o modelo\n",
        "classificador = MLPClassifier(hidden_layer_sizes = (100), activation = 'logistic', max_iter = 1000)\n",
        "\n",
        "#calculando os scores\n",
        "scores = cross_val_score(classificador,X,y,cv=10)\n",
        "scores"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.63333333, 0.86666667, 0.86666667, 0.83333333, 0.93333333,\n",
              "       0.9       , 0.86666667, 0.86666667, 0.7       , 0.68965517])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lG03z2ljfAQ1",
        "colab_type": "text"
      },
      "source": [
        "Aqui podemos ver que em um dos casos o score atingiu 0.93 em quanto em outro chegou a 0.63 mostrando que seria uma questão de sorte conseguir testar o modelo para que o score seja o mais alto, sendo que na maioria dos outos o score é baixo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TPqKO_Pe21K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e1653e6b-6989-47b6-b095-c6dbce704e44"
      },
      "source": [
        "round(scores.mean(),3),round(scores.std(),3)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.816, 0.097)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxNoee5dfS5g",
        "colab_type": "text"
      },
      "source": [
        "Aqui mostra a média e o desvio padrão do scores, podemos perdeber que a média de 0.8 é relativamente baixa para o problema."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "072kDzMffk_w",
        "colab_type": "text"
      },
      "source": [
        "## "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14n27c-ufp5j",
        "colab_type": "text"
      },
      "source": [
        "## 6. Comparando MLP com Árvore de Decisão e Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxppFXoVf33q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7cda3aab-276b-4a20-da35-37a1470fb2e0"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#criando a árvore\n",
        "arvore = DecisionTreeClassifier()\n",
        "#calcular scores\n",
        "scores_arvore = cross_val_score(arvore,X,y,cv = 10)\n",
        "\n",
        "#criando random forest\n",
        "floresta = RandomForestClassifier()\n",
        "#calcular scores\n",
        "scores_floresta = cross_val_score(floresta,X,y,cv = 10)\n",
        "\n",
        "#criando rede neural\n",
        "mlp = MLPClassifier(hidden_layer_sizes = (100), activation='logistic', max_iter = 1000)\n",
        "#calcular scores\n",
        "scores_mlp = cross_val_score(mlp,X,y,cv = 10)\n",
        "\n",
        "print('Árvore de Decisão: ', round(scores_arvore.mean(),3), round(scores_arvore.std(),3))\n",
        "print('Random Forest: ', round(scores.mean(),3), round(scores.std(),3))\n",
        "print('MLP: ', round(scores_mlp.mean(),3), round(scores_mlp.std(),3))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Árvore de Decisão:  0.699 0.153\n",
            "Random Forest:  0.816 0.097\n",
            "MLP:  0.806 0.094\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqcu8pNFhbnX",
        "colab_type": "text"
      },
      "source": [
        "Aqui podemos ver que o melhor classificador é a rede neural, que mesmo sendo o melhor não traz um bom resultado para o problema mostrado. E como já era de se esperar a Random Forest se saiu melhor que uma única árvore, pois a random como é um conjunto de árvores tem mais possibilidade de acerto. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abPwebyAhz2V",
        "colab_type": "text"
      },
      "source": [
        "### 7. Otimizando Parâmetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoKVZbhNh_Im",
        "colab_type": "text"
      },
      "source": [
        "#### Random Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a151-5okiBjF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "84f3e5c6-d913-4b4f-84ef-5d15ea4bb49d"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_grid = [ \n",
        "              {\n",
        "                  'hidden_layer_sizes' : [(10),(50),(100),(50,10),(100,50)],\n",
        "                  'activation' : ['identity','logistic','tanh','relu'],\n",
        "                  'solver' : ['lbfgs', 'sgd', 'adam'],\n",
        "                  'max_iter' : [500,1000,2000]\n",
        "              }\n",
        "]\n",
        "import time\n",
        "ini = time.time()\n",
        "\n",
        "mlp = RandomizedSearchCV(MLPClassifier(), param_grid,cv = 5, scoring ='accuracy')\n",
        "mlp.fit(X,y)\n",
        "fim = time.time()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzbRN3NdjBia",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "39ca198b-d986-4417-a10b-99840f064158"
      },
      "source": [
        "print(mlp.best_params_)\n",
        "print('Tempo de resposta do Randomized Search: {:.2f} segundos'.format(fim-ini))\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'solver': 'adam', 'max_iter': 500, 'hidden_layer_sizes': 100, 'activation': 'tanh'}\n",
            "Tempo de resposta do Randomized Search: 28.61 segundos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiclrHxejMkM",
        "colab_type": "text"
      },
      "source": [
        "Aqui encontramos os melhores parâmentros para a rede neural, dessa forma os parâmetros foram encontrados de forma aleatória, sendo não necessariamente os melhores possíveis, mas de uma forma aleatória de teste os melhores encontrados, essa forma tem menos custo computacional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5FLPspKjH8K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a5d38ce-d8e0-435f-f505-9a86b95c981d"
      },
      "source": [
        "print(round(mlp.best_score_,3))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suwyun3Ljd8b",
        "colab_type": "text"
      },
      "source": [
        "Aqui tem a score da rede, podemos ver que mesmo com o melhores parâmetros encotrados de forma aleatória o resultado não é bom, sendo até pior que alguns scores encontrados anteriormente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjT_kaxtjvwX",
        "colab_type": "text"
      },
      "source": [
        "#### Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMH9NgknjzPu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cdeec062-528d-4b2c-86cf-f75bd2a1f7ac"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "ini = time.time()\n",
        "mlp = GridSearchCV(MLPClassifier(), param_grid, cv = 5, scoring = 'accuracy')\n",
        "mlp.fit(X,y)\n",
        "fim = time.time()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Idu69bskMVJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "54897b06-09b4-4e5e-e6b2-39da343f6e89"
      },
      "source": [
        "\n",
        "print(mlp.best_params_)\n",
        "print('Tempo de resposta do Grid Search: {:.2f} segundos'.format(fim-ini))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'activation': 'identity', 'hidden_layer_sizes': (100, 50), 'max_iter': 500, 'solver': 'adam'}\n",
            "Tempo de resposta do Grid Search: 600.22 segundos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn9jwdQelCcF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1fd3f134-0058-45b2-dad6-0067dd294d19"
      },
      "source": [
        "print(mlp.best_score_)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7989265536723164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSjpFmONlHbe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e06a31d2-cfde-4b96-ce47-f4d6cc94afb0"
      },
      "source": [
        "mlp.cv_results_"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([0.01577539, 0.25515203, 0.31332221, 0.01185946, 0.48457479,\n",
              "        0.39860168, 0.01092267, 0.57844267, 0.37119951, 0.02569971,\n",
              "        0.51808176, 0.36163173, 0.02722368, 0.8618216 , 0.39350128,\n",
              "        0.02414126, 0.89776239, 0.39511695, 0.03084459, 0.58133407,\n",
              "        0.38699117, 0.0306098 , 0.96604271, 0.36548672, 0.0332119 ,\n",
              "        1.09248362, 0.38009305, 0.03039188, 0.40189924, 0.20175037,\n",
              "        0.02197061, 0.56509147, 0.17568293, 0.02161407, 0.58554864,\n",
              "        0.18961825, 0.08061519, 0.9613019 , 0.26292014, 0.07147622,\n",
              "        1.41577835, 0.2308064 , 0.08024788, 1.41772814, 0.24389825,\n",
              "        0.10807304, 0.06737437, 0.35028462, 0.11839423, 0.05962305,\n",
              "        0.68317461, 0.09063649, 0.06823473, 0.7903697 , 0.24005079,\n",
              "        0.07138324, 0.82785211, 0.24118409, 0.07935677, 1.20755649,\n",
              "        0.25286651, 0.05772243, 1.16976061, 0.45792027, 0.06439795,\n",
              "        1.15493817, 0.46746197, 0.0619493 , 1.46861062, 0.43524957,\n",
              "        0.07176695, 1.48108993, 0.36719995, 0.10783625, 0.1873291 ,\n",
              "        0.33121176, 0.08015113, 0.19657383, 0.29214334, 0.09815803,\n",
              "        0.22977624, 0.9094738 , 0.1468585 , 1.09346781, 0.86762981,\n",
              "        0.14502273, 0.85748105, 1.22905235, 0.14460568, 1.01864705,\n",
              "        0.16014538, 0.31905522, 0.36761112, 0.1192296 , 0.62015123,\n",
              "        0.48135924, 0.15936623, 0.87136517, 0.46541057, 0.22516432,\n",
              "        0.81525254, 0.65405469, 0.20770164, 1.92961917, 1.44317188,\n",
              "        0.25652976, 1.67959189, 0.70515795, 0.44459271, 1.18128724,\n",
              "        0.67964978, 0.42804179, 2.21833186, 0.72032752, 0.39137435,\n",
              "        2.26709003, 0.7588562 , 0.21210141, 0.67407331, 0.46847329,\n",
              "        0.21142545, 1.10752916, 0.63978376, 0.17647691, 1.16280484,\n",
              "        0.79081054, 0.71560245, 1.84723072, 0.51847534, 0.65158134,\n",
              "        3.08215919, 0.38968139, 0.6046639 , 2.81831079, 0.46900992,\n",
              "        0.18620281, 0.29292016, 0.38876429, 0.24013901, 0.67118936,\n",
              "        0.53830366, 0.26538682, 0.60202661, 0.49636679, 0.25003943,\n",
              "        0.71066527, 0.77905517, 0.23591971, 1.37413816, 1.31542673,\n",
              "        0.20234227, 1.88273005, 1.55865102, 0.36211176, 0.91703124,\n",
              "        0.97253051, 0.35425754, 1.75807548, 1.73866239, 0.3269455 ,\n",
              "        2.1923038 , 2.70413694, 0.18797774, 0.51016712, 0.67351527,\n",
              "        0.16701283, 1.20387664, 1.14621935, 0.10799627, 1.547469  ,\n",
              "        1.13398762, 0.58366537, 1.45781126, 1.5895884 , 0.49674444,\n",
              "        2.96485219, 2.0953372 , 0.58924193, 3.41589489, 1.97126789]),\n",
              " 'mean_score_time': array([0.00143709, 0.00175257, 0.00158348, 0.00130382, 0.00169888,\n",
              "        0.00131087, 0.00118761, 0.00134382, 0.00130701, 0.00169439,\n",
              "        0.00430951, 0.00175223, 0.00181475, 0.00178509, 0.00177293,\n",
              "        0.00175014, 0.00179152, 0.00177865, 0.00176311, 0.00203114,\n",
              "        0.00177903, 0.00177364, 0.0018856 , 0.00181561, 0.00175962,\n",
              "        0.00181441, 0.00181184, 0.00162101, 0.00190716, 0.00133018,\n",
              "        0.00135961, 0.00138178, 0.00133576, 0.00135446, 0.0013423 ,\n",
              "        0.00136003, 0.00232801, 0.00181785, 0.00188255, 0.00183229,\n",
              "        0.00185962, 0.00186868, 0.00184169, 0.00188479, 0.00186267,\n",
              "        0.00133662, 0.0013443 , 0.00186954, 0.00133438, 0.00134778,\n",
              "        0.00172391, 0.0013576 , 0.00140643, 0.00134468, 0.0019021 ,\n",
              "        0.0018887 , 0.00194826, 0.00188656, 0.00187888, 0.00185671,\n",
              "        0.00195179, 0.00185952, 0.00187426, 0.00208349, 0.00208478,\n",
              "        0.0020565 , 0.00200648, 0.00199304, 0.00205717, 0.00202994,\n",
              "        0.00200157, 0.00201154, 0.00143356, 0.00144053, 0.00156898,\n",
              "        0.0014205 , 0.00146637, 0.00146952, 0.00143275, 0.00143924,\n",
              "        0.0014338 , 0.00223012, 0.00222659, 0.00223694, 0.0021605 ,\n",
              "        0.00217638, 0.00218801, 0.00221987, 0.00225306, 0.00220194,\n",
              "        0.00154352, 0.00193954, 0.00183973, 0.00135407, 0.00164804,\n",
              "        0.0013536 , 0.00132523, 0.00135808, 0.0013485 , 0.00195541,\n",
              "        0.0018961 , 0.00188799, 0.00193715, 0.00255637, 0.0053874 ,\n",
              "        0.00191197, 0.00200849, 0.00196223, 0.00218105, 0.00203753,\n",
              "        0.00202923, 0.00212884, 0.00206809, 0.00209756, 0.00229659,\n",
              "        0.00206261, 0.00205235, 0.00151892, 0.00195022, 0.00156512,\n",
              "        0.00148783, 0.00146484, 0.00155163, 0.00147605, 0.00150294,\n",
              "        0.00148749, 0.00237617, 0.00220442, 0.00234952, 0.00237265,\n",
              "        0.00230694, 0.00225101, 0.00232711, 0.00226898, 0.00237279,\n",
              "        0.00163794, 0.00167241, 0.00175395, 0.00135713, 0.00171752,\n",
              "        0.0013411 , 0.00138879, 0.00135446, 0.00138407, 0.00187845,\n",
              "        0.00192437, 0.00221038, 0.00187359, 0.00193725, 0.00189757,\n",
              "        0.0018517 , 0.00185504, 0.00182633, 0.00192332, 0.00193777,\n",
              "        0.00184751, 0.0018815 , 0.00185585, 0.00193028, 0.00187073,\n",
              "        0.00188384, 0.0019485 , 0.00143075, 0.00192513, 0.00192537,\n",
              "        0.00152001, 0.00183101, 0.00164595, 0.00139709, 0.00144978,\n",
              "        0.00144954, 0.00203462, 0.00212255, 0.00220962, 0.00205159,\n",
              "        0.00219069, 0.00202684, 0.00201607, 0.00203481, 0.0022665 ]),\n",
              " 'mean_test_score': array([0.76892655, 0.71225989, 0.76559322, 0.76892655, 0.75559322,\n",
              "        0.78892655, 0.76892655, 0.75559322, 0.78225989, 0.76559322,\n",
              "        0.74225989, 0.77559322, 0.76892655, 0.75559322, 0.78892655,\n",
              "        0.76892655, 0.75225989, 0.77892655, 0.76892655, 0.74892655,\n",
              "        0.77892655, 0.76559322, 0.74559322, 0.79225989, 0.76892655,\n",
              "        0.74892655, 0.78892655, 0.76892655, 0.76225989, 0.78559322,\n",
              "        0.76892655, 0.77892655, 0.79225989, 0.76559322, 0.77225989,\n",
              "        0.78892655, 0.76559322, 0.76225989, 0.79892655, 0.76559322,\n",
              "        0.77559322, 0.77892655, 0.76892655, 0.76559322, 0.77892655,\n",
              "        0.66225989, 0.67892655, 0.71559322, 0.67559322, 0.67892655,\n",
              "        0.77225989, 0.66898305, 0.67892655, 0.77225989, 0.68892655,\n",
              "        0.67892655, 0.77559322, 0.69231638, 0.67892655, 0.79559322,\n",
              "        0.66559322, 0.67892655, 0.78892655, 0.63898305, 0.67892655,\n",
              "        0.78225989, 0.66892655, 0.67892655, 0.78892655, 0.65892655,\n",
              "        0.67892655, 0.79892655, 0.69231638, 0.67892655, 0.69892655,\n",
              "        0.66898305, 0.67892655, 0.71892655, 0.64553672, 0.67892655,\n",
              "        0.69892655, 0.68898305, 0.67892655, 0.77559322, 0.66564972,\n",
              "        0.67892655, 0.78559322, 0.67225989, 0.67892655, 0.76225989,\n",
              "        0.66225989, 0.68559322, 0.77559322, 0.63564972, 0.76559322,\n",
              "        0.78225989, 0.66559322, 0.75559322, 0.78225989, 0.67225989,\n",
              "        0.71559322, 0.78559322, 0.69559322, 0.75892655, 0.78559322,\n",
              "        0.64225989, 0.76559322, 0.79225989, 0.67225989, 0.73892655,\n",
              "        0.79225989, 0.67892655, 0.75892655, 0.79559322, 0.66559322,\n",
              "        0.75225989, 0.78225989, 0.70559322, 0.73892655, 0.75225989,\n",
              "        0.68892655, 0.77225989, 0.75892655, 0.70559322, 0.74559322,\n",
              "        0.74225989, 0.64892655, 0.76225989, 0.79225989, 0.69559322,\n",
              "        0.75892655, 0.77892655, 0.63892655, 0.77225989, 0.77559322,\n",
              "        0.70242938, 0.71225989, 0.78892655, 0.69570621, 0.76559322,\n",
              "        0.78225989, 0.69225989, 0.73225989, 0.77559322, 0.64559322,\n",
              "        0.69225989, 0.75559322, 0.72564972, 0.75559322, 0.76225989,\n",
              "        0.65903955, 0.75559322, 0.75892655, 0.69231638, 0.70559322,\n",
              "        0.78225989, 0.69898305, 0.76225989, 0.72892655, 0.68564972,\n",
              "        0.75225989, 0.74559322, 0.68231638, 0.69225989, 0.74892655,\n",
              "        0.70564972, 0.74225989, 0.72225989, 0.65892655, 0.77225989,\n",
              "        0.72225989, 0.66559322, 0.73892655, 0.69892655, 0.67231638,\n",
              "        0.77225989, 0.69559322, 0.68564972, 0.76892655, 0.68898305]),\n",
              " 'param_activation': masked_array(data=['identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_hidden_layer_sizes': masked_array(data=[10, 10, 10, 10, 10, 10, 10, 10, 10, 50, 50, 50, 50, 50,\n",
              "                    50, 50, 50, 50, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, (50, 10), (50, 10), (50, 10), (50, 10), (50, 10),\n",
              "                    (50, 10), (50, 10), (50, 10), (50, 10), (100, 50),\n",
              "                    (100, 50), (100, 50), (100, 50), (100, 50), (100, 50),\n",
              "                    (100, 50), (100, 50), (100, 50), 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 100, 100, (50, 10),\n",
              "                    (50, 10), (50, 10), (50, 10), (50, 10), (50, 10),\n",
              "                    (50, 10), (50, 10), (50, 10), (100, 50), (100, 50),\n",
              "                    (100, 50), (100, 50), (100, 50), (100, 50), (100, 50),\n",
              "                    (100, 50), (100, 50), 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 50, 50, 50, 50, 50, 50, 50, 50, 50, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 100, (50, 10), (50, 10),\n",
              "                    (50, 10), (50, 10), (50, 10), (50, 10), (50, 10),\n",
              "                    (50, 10), (50, 10), (100, 50), (100, 50), (100, 50),\n",
              "                    (100, 50), (100, 50), (100, 50), (100, 50), (100, 50),\n",
              "                    (100, 50), 10, 10, 10, 10, 10, 10, 10, 10, 10, 50, 50,\n",
              "                    50, 50, 50, 50, 50, 50, 50, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, (50, 10), (50, 10), (50, 10),\n",
              "                    (50, 10), (50, 10), (50, 10), (50, 10), (50, 10),\n",
              "                    (50, 10), (100, 50), (100, 50), (100, 50), (100, 50),\n",
              "                    (100, 50), (100, 50), (100, 50), (100, 50), (100, 50)],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_max_iter': masked_array(data=[500, 500, 500, 1000, 1000, 1000, 2000, 2000, 2000, 500,\n",
              "                    500, 500, 1000, 1000, 1000, 2000, 2000, 2000, 500, 500,\n",
              "                    500, 1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_solver': masked_array(data=['lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'}],\n",
              " 'rank_test_score': array([ 48, 111,  59,  48,  82,  10,  48,  82,  21,  63,  97,  34,  48,\n",
              "         80,  10,  48,  87,  28,  48,  91,  28,  63,  95,   5,  48,  91,\n",
              "         10,  48,  73,  17,  48,  28,   5,  63,  41,  10,  63,  70,   1,\n",
              "         63,  34,  28,  48,  59,  28, 169, 140, 109, 156, 140,  41, 161,\n",
              "        140,  41, 134, 140,  34, 126, 140,   3, 166, 140,  10, 178, 140,\n",
              "         21, 163, 140,  10, 172, 140,   1, 126, 140, 119, 161, 140, 108,\n",
              "        176, 140, 119, 132, 140,  34, 164, 140,  17, 158, 140,  70, 169,\n",
              "        138,  34, 180,  59,  21, 166,  82,  21, 160, 109,  17, 123,  75,\n",
              "         17, 177,  59,   5, 158, 100,   5, 140,  75,   3, 165,  89,  21,\n",
              "        114, 100,  89, 134,  47,  79, 114,  95,  97, 174,  70,   5, 123,\n",
              "         75,  33, 179,  41,  34, 117, 111,  10, 122,  68,  21, 129, 103,\n",
              "         34, 175, 130,  82, 105,  82,  69, 171,  80,  75, 126, 114,  21,\n",
              "        118,  73, 104, 136,  87,  94, 139, 130,  91, 113,  97, 106, 172,\n",
              "         41, 106, 166, 100, 119, 157,  41, 123, 136,  58, 132], dtype=int32),\n",
              " 'split0_test_score': array([0.65      , 0.71666667, 0.7       , 0.65      , 0.7       ,\n",
              "        0.71666667, 0.65      , 0.7       , 0.7       , 0.65      ,\n",
              "        0.76666667, 0.71666667, 0.65      , 0.71666667, 0.71666667,\n",
              "        0.65      , 0.71666667, 0.7       , 0.65      , 0.81666667,\n",
              "        0.66666667, 0.65      , 0.66666667, 0.71666667, 0.65      ,\n",
              "        0.66666667, 0.7       , 0.65      , 0.66666667, 0.66666667,\n",
              "        0.65      , 0.71666667, 0.7       , 0.65      , 0.66666667,\n",
              "        0.68333333, 0.65      , 0.71666667, 0.71666667, 0.65      ,\n",
              "        0.65      , 0.65      , 0.65      , 0.65      , 0.65      ,\n",
              "        0.53333333, 0.66666667, 0.76666667, 0.7       , 0.66666667,\n",
              "        0.7       , 0.56666667, 0.66666667, 0.7       , 0.63333333,\n",
              "        0.66666667, 0.7       , 0.53333333, 0.66666667, 0.7       ,\n",
              "        0.63333333, 0.66666667, 0.68333333, 0.55      , 0.66666667,\n",
              "        0.71666667, 0.6       , 0.66666667, 0.7       , 0.53333333,\n",
              "        0.66666667, 0.7       , 0.7       , 0.66666667, 0.66666667,\n",
              "        0.56666667, 0.66666667, 0.66666667, 0.61666667, 0.66666667,\n",
              "        0.66666667, 0.71666667, 0.66666667, 0.66666667, 0.6       ,\n",
              "        0.66666667, 0.66666667, 0.56666667, 0.66666667, 0.68333333,\n",
              "        0.65      , 0.7       , 0.7       , 0.55      , 0.78333333,\n",
              "        0.7       , 0.61666667, 0.66666667, 0.7       , 0.6       ,\n",
              "        0.68333333, 0.68333333, 0.61666667, 0.73333333, 0.66666667,\n",
              "        0.55      , 0.75      , 0.66666667, 0.58333333, 0.78333333,\n",
              "        0.7       , 0.68333333, 0.71666667, 0.73333333, 0.6       ,\n",
              "        0.71666667, 0.66666667, 0.6       , 0.7       , 0.63333333,\n",
              "        0.58333333, 0.68333333, 0.61666667, 0.66666667, 0.58333333,\n",
              "        0.63333333, 0.53333333, 0.68333333, 0.71666667, 0.61666667,\n",
              "        0.58333333, 0.63333333, 0.58333333, 0.65      , 0.6       ,\n",
              "        0.61666667, 0.76666667, 0.71666667, 0.58333333, 0.81666667,\n",
              "        0.65      , 0.53333333, 0.66666667, 0.7       , 0.53333333,\n",
              "        0.66666667, 0.63333333, 0.65      , 0.75      , 0.65      ,\n",
              "        0.53333333, 0.73333333, 0.65      , 0.58333333, 0.73333333,\n",
              "        0.7       , 0.58333333, 0.81666667, 0.6       , 0.53333333,\n",
              "        0.71666667, 0.65      , 0.55      , 0.66666667, 0.61666667,\n",
              "        0.56666667, 0.58333333, 0.55      , 0.6       , 0.61666667,\n",
              "        0.6       , 0.56666667, 0.85      , 0.55      , 0.61666667,\n",
              "        0.7       , 0.51666667, 0.53333333, 0.6       , 0.58333333]),\n",
              " 'split1_test_score': array([0.76666667, 0.75      , 0.8       , 0.76666667, 0.86666667,\n",
              "        0.8       , 0.76666667, 0.86666667, 0.8       , 0.76666667,\n",
              "        0.83333333, 0.8       , 0.76666667, 0.86666667, 0.8       ,\n",
              "        0.76666667, 0.86666667, 0.8       , 0.76666667, 0.83333333,\n",
              "        0.8       , 0.76666667, 0.86666667, 0.8       , 0.76666667,\n",
              "        0.86666667, 0.81666667, 0.76666667, 0.83333333, 0.8       ,\n",
              "        0.76666667, 0.8       , 0.81666667, 0.76666667, 0.86666667,\n",
              "        0.8       , 0.76666667, 0.85      , 0.78333333, 0.76666667,\n",
              "        0.83333333, 0.8       , 0.76666667, 0.85      , 0.8       ,\n",
              "        0.61666667, 0.68333333, 0.75      , 0.73333333, 0.68333333,\n",
              "        0.81666667, 0.78333333, 0.68333333, 0.8       , 0.8       ,\n",
              "        0.68333333, 0.85      , 0.78333333, 0.68333333, 0.81666667,\n",
              "        0.7       , 0.68333333, 0.83333333, 0.56666667, 0.68333333,\n",
              "        0.83333333, 0.66666667, 0.68333333, 0.8       , 0.75      ,\n",
              "        0.68333333, 0.81666667, 0.66666667, 0.68333333, 0.78333333,\n",
              "        0.71666667, 0.68333333, 0.68333333, 0.63333333, 0.68333333,\n",
              "        0.78333333, 0.65      , 0.68333333, 0.81666667, 0.56666667,\n",
              "        0.68333333, 0.81666667, 0.7       , 0.68333333, 0.68333333,\n",
              "        0.61666667, 0.68333333, 0.81666667, 0.65      , 0.9       ,\n",
              "        0.81666667, 0.63333333, 0.86666667, 0.8       , 0.66666667,\n",
              "        0.76666667, 0.8       , 0.68333333, 0.86666667, 0.81666667,\n",
              "        0.56666667, 0.88333333, 0.83333333, 0.56666667, 0.81666667,\n",
              "        0.8       , 0.58333333, 0.85      , 0.8       , 0.65      ,\n",
              "        0.85      , 0.81666667, 0.71666667, 0.83333333, 0.81666667,\n",
              "        0.66666667, 0.85      , 0.8       , 0.71666667, 0.86666667,\n",
              "        0.81666667, 0.63333333, 0.83333333, 0.81666667, 0.65      ,\n",
              "        0.85      , 0.81666667, 0.58333333, 0.86666667, 0.8       ,\n",
              "        0.8       , 0.75      , 0.83333333, 0.7       , 0.85      ,\n",
              "        0.81666667, 0.68333333, 0.85      , 0.8       , 0.63333333,\n",
              "        0.71666667, 0.78333333, 0.76666667, 0.88333333, 0.81666667,\n",
              "        0.63333333, 0.86666667, 0.78333333, 0.73333333, 0.73333333,\n",
              "        0.81666667, 0.66666667, 0.85      , 0.76666667, 0.71666667,\n",
              "        0.88333333, 0.8       , 0.71666667, 0.75      , 0.8       ,\n",
              "        0.78333333, 0.9       , 0.78333333, 0.63333333, 0.86666667,\n",
              "        0.76666667, 0.7       , 0.76666667, 0.75      , 0.66666667,\n",
              "        0.86666667, 0.73333333, 0.7       , 0.85      , 0.63333333]),\n",
              " 'split2_test_score': array([0.9       , 0.73333333, 0.83333333, 0.9       , 0.83333333,\n",
              "        0.86666667, 0.9       , 0.85      , 0.86666667, 0.88333333,\n",
              "        0.73333333, 0.86666667, 0.9       , 0.81666667, 0.86666667,\n",
              "        0.9       , 0.8       , 0.85      , 0.9       , 0.73333333,\n",
              "        0.86666667, 0.88333333, 0.81666667, 0.88333333, 0.9       ,\n",
              "        0.81666667, 0.86666667, 0.9       , 0.81666667, 0.88333333,\n",
              "        0.9       , 0.88333333, 0.88333333, 0.88333333, 0.85      ,\n",
              "        0.88333333, 0.88333333, 0.81666667, 0.9       , 0.88333333,\n",
              "        0.9       , 0.91666667, 0.9       , 0.83333333, 0.86666667,\n",
              "        0.81666667, 0.68333333, 0.7       , 0.6       , 0.68333333,\n",
              "        0.83333333, 0.68333333, 0.68333333, 0.83333333, 0.66666667,\n",
              "        0.68333333, 0.85      , 0.76666667, 0.68333333, 0.9       ,\n",
              "        0.68333333, 0.68333333, 0.86666667, 0.73333333, 0.68333333,\n",
              "        0.86666667, 0.76666667, 0.68333333, 0.88333333, 0.7       ,\n",
              "        0.68333333, 0.91666667, 0.76666667, 0.68333333, 0.68333333,\n",
              "        0.76666667, 0.68333333, 0.88333333, 0.76666667, 0.68333333,\n",
              "        0.68333333, 0.76666667, 0.68333333, 0.9       , 0.78333333,\n",
              "        0.68333333, 0.88333333, 0.73333333, 0.68333333, 0.9       ,\n",
              "        0.61666667, 0.68333333, 0.81666667, 0.66666667, 0.76666667,\n",
              "        0.86666667, 0.78333333, 0.81666667, 0.85      , 0.78333333,\n",
              "        0.76666667, 0.88333333, 0.8       , 0.8       , 0.88333333,\n",
              "        0.73333333, 0.81666667, 0.9       , 0.85      , 0.73333333,\n",
              "        0.9       , 0.76666667, 0.83333333, 0.88333333, 0.71666667,\n",
              "        0.83333333, 0.85      , 0.83333333, 0.8       , 0.86666667,\n",
              "        0.76666667, 0.86666667, 0.88333333, 0.78333333, 0.81666667,\n",
              "        0.86666667, 0.71666667, 0.85      , 0.91666667, 0.81666667,\n",
              "        0.9       , 0.88333333, 0.71666667, 0.86666667, 0.88333333,\n",
              "        0.68333333, 0.68333333, 0.83333333, 0.73333333, 0.78333333,\n",
              "        0.86666667, 0.85      , 0.78333333, 0.81666667, 0.73333333,\n",
              "        0.71666667, 0.86666667, 0.81666667, 0.76666667, 0.85      ,\n",
              "        0.66666667, 0.8       , 0.9       , 0.73333333, 0.7       ,\n",
              "        0.88333333, 0.8       , 0.78333333, 0.85      , 0.76666667,\n",
              "        0.8       , 0.83333333, 0.76666667, 0.68333333, 0.85      ,\n",
              "        0.78333333, 0.78333333, 0.83333333, 0.7       , 0.85      ,\n",
              "        0.85      , 0.75      , 0.71666667, 0.78333333, 0.7       ,\n",
              "        0.81666667, 0.8       , 0.8       , 0.83333333, 0.81666667]),\n",
              " 'split3_test_score': array([0.85      , 0.68333333, 0.81666667, 0.85      , 0.7       ,\n",
              "        0.88333333, 0.85      , 0.68333333, 0.86666667, 0.85      ,\n",
              "        0.7       , 0.81666667, 0.85      , 0.7       , 0.88333333,\n",
              "        0.85      , 0.7       , 0.86666667, 0.85      , 0.68333333,\n",
              "        0.88333333, 0.85      , 0.7       , 0.88333333, 0.85      ,\n",
              "        0.71666667, 0.88333333, 0.85      , 0.81666667, 0.9       ,\n",
              "        0.85      , 0.81666667, 0.88333333, 0.85      , 0.8       ,\n",
              "        0.9       , 0.85      , 0.75      , 0.91666667, 0.85      ,\n",
              "        0.81666667, 0.85      , 0.85      , 0.81666667, 0.9       ,\n",
              "        0.66666667, 0.68333333, 0.68333333, 0.66666667, 0.68333333,\n",
              "        0.83333333, 0.61666667, 0.68333333, 0.85      , 0.66666667,\n",
              "        0.68333333, 0.8       , 0.68333333, 0.68333333, 0.88333333,\n",
              "        0.63333333, 0.68333333, 0.88333333, 0.65      , 0.68333333,\n",
              "        0.81666667, 0.63333333, 0.68333333, 0.88333333, 0.63333333,\n",
              "        0.68333333, 0.88333333, 0.63333333, 0.68333333, 0.68333333,\n",
              "        0.6       , 0.68333333, 0.68333333, 0.55      , 0.68333333,\n",
              "        0.68333333, 0.61666667, 0.68333333, 0.81666667, 0.68333333,\n",
              "        0.68333333, 0.88333333, 0.68333333, 0.68333333, 0.86666667,\n",
              "        0.75      , 0.68333333, 0.86666667, 0.61666667, 0.7       ,\n",
              "        0.85      , 0.61666667, 0.75      , 0.88333333, 0.63333333,\n",
              "        0.68333333, 0.88333333, 0.7       , 0.71666667, 0.88333333,\n",
              "        0.68333333, 0.7       , 0.88333333, 0.68333333, 0.68333333,\n",
              "        0.88333333, 0.68333333, 0.71666667, 0.88333333, 0.68333333,\n",
              "        0.68333333, 0.9       , 0.7       , 0.68333333, 0.76666667,\n",
              "        0.75      , 0.78333333, 0.81666667, 0.68333333, 0.78333333,\n",
              "        0.71666667, 0.68333333, 0.76666667, 0.83333333, 0.71666667,\n",
              "        0.78333333, 0.88333333, 0.63333333, 0.8       , 0.91666667,\n",
              "        0.68333333, 0.68333333, 0.88333333, 0.75      , 0.7       ,\n",
              "        0.9       , 0.71666667, 0.68333333, 0.88333333, 0.65      ,\n",
              "        0.68333333, 0.81666667, 0.7       , 0.7       , 0.81666667,\n",
              "        0.75      , 0.7       , 0.78333333, 0.71666667, 0.68333333,\n",
              "        0.83333333, 0.75      , 0.68333333, 0.75      , 0.71666667,\n",
              "        0.68333333, 0.76666667, 0.68333333, 0.68333333, 0.8       ,\n",
              "        0.7       , 0.76666667, 0.76666667, 0.68333333, 0.85      ,\n",
              "        0.71666667, 0.63333333, 0.68333333, 0.73333333, 0.68333333,\n",
              "        0.8       , 0.75      , 0.7       , 0.88333333, 0.71666667]),\n",
              " 'split4_test_score': array([0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.69491525, 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.69491525, 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.69491525, 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.69491525, 0.6779661 , 0.6779661 ,\n",
              "        0.69491525, 0.6779661 , 0.6779661 , 0.66101695, 0.6779661 ,\n",
              "        0.6779661 , 0.69491525, 0.6779661 , 0.6779661 , 0.69491525,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.69491525, 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.72881356, 0.6779661 , 0.6779661 , 0.71186441, 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.69491525, 0.6779661 , 0.6779661 ,\n",
              "        0.71186441, 0.6779661 , 0.6779661 , 0.69491525, 0.6779661 ,\n",
              "        0.6779661 , 0.69491525, 0.6779661 , 0.6779661 , 0.69491525,\n",
              "        0.6779661 , 0.6779661 , 0.69491525, 0.6779661 , 0.6779661 ,\n",
              "        0.69491525, 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
              "        0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.69491525,\n",
              "        0.6779661 , 0.6779661 , 0.69491525, 0.6779661 , 0.69491525]),\n",
              " 'std_fit_time': array([0.00684562, 0.01963767, 0.01037419, 0.00145818, 0.04523972,\n",
              "        0.09344079, 0.00131429, 0.07183401, 0.07029137, 0.00249354,\n",
              "        0.0426221 , 0.09488641, 0.00751362, 0.08630984, 0.07323566,\n",
              "        0.00170589, 0.14694227, 0.04289608, 0.00194393, 0.0086412 ,\n",
              "        0.07025532, 0.00245644, 0.12483386, 0.01826183, 0.00360124,\n",
              "        0.24159803, 0.06224054, 0.00476068, 0.00845906, 0.06520343,\n",
              "        0.00109602, 0.03405854, 0.01851638, 0.00203971, 0.07206574,\n",
              "        0.03556674, 0.01311825, 0.01584075, 0.02360096, 0.00824582,\n",
              "        0.15138916, 0.02623009, 0.0060662 , 0.15851013, 0.0344066 ,\n",
              "        0.07185422, 0.02311786, 0.00839323, 0.04406019, 0.02834519,\n",
              "        0.00862962, 0.0201168 , 0.01722933, 0.11114598, 0.04051947,\n",
              "        0.00659703, 0.00900744, 0.02497291, 0.02012234, 0.15277595,\n",
              "        0.03510299, 0.01872612, 0.18094077, 0.08014616, 0.01092356,\n",
              "        0.02310337, 0.08251964, 0.00748412, 0.22820912, 0.08895142,\n",
              "        0.00498839, 0.15269194, 0.07524861, 0.03903155, 0.23523788,\n",
              "        0.05997633, 0.02551091, 0.23335705, 0.08441908, 0.02196809,\n",
              "        0.30866823, 0.44238109, 0.01916031, 0.55842505, 0.42462709,\n",
              "        0.02529442, 0.63592833, 0.32090122, 0.02331539, 0.49605541,\n",
              "        0.05374324, 0.00753447, 0.00453711, 0.02770803, 0.01771931,\n",
              "        0.1241636 , 0.04537643, 0.09451874, 0.03677226, 0.04949824,\n",
              "        0.02190342, 0.12563716, 0.05015206, 0.72865694, 0.26165266,\n",
              "        0.05991477, 0.30524749, 0.14501576, 0.04066341, 0.0143601 ,\n",
              "        0.10708683, 0.07844027, 0.09852357, 0.19155097, 0.07315306,\n",
              "        0.46823049, 0.13859357, 0.08255608, 0.00840644, 0.14120126,\n",
              "        0.11290921, 0.09924894, 0.43769837, 0.06286242, 0.16148082,\n",
              "        0.73038873, 0.14282027, 0.02535273, 0.03580485, 0.24360268,\n",
              "        0.337816  , 0.03440066, 0.11548778, 0.31032482, 0.04165985,\n",
              "        0.04434285, 0.10112183, 0.02031238, 0.1099502 , 0.01399747,\n",
              "        0.06613749, 0.04624269, 0.42808624, 0.04471318, 0.08924171,\n",
              "        0.00714559, 0.02581918, 0.06499701, 0.03504317, 0.31345389,\n",
              "        0.03199646, 0.22858048, 0.77648534, 0.11210698, 0.01340095,\n",
              "        0.01332631, 0.10993279, 0.09428874, 0.30466182, 0.11598892,\n",
              "        0.28124873, 0.62052559, 0.03403329, 0.24711316, 0.00478368,\n",
              "        0.02329042, 0.01640049, 0.19717502, 0.08233351, 0.2130444 ,\n",
              "        0.27130025, 0.13830728, 0.02296539, 0.01134117, 0.07482381,\n",
              "        0.09119474, 0.42567171, 0.16039354, 0.17206117, 0.45073356]),\n",
              " 'std_score_time': array([2.60461559e-04, 3.18329587e-04, 2.33475299e-04, 9.16928967e-05,\n",
              "        3.02984394e-04, 2.45991597e-05, 5.05491021e-05, 4.28736272e-05,\n",
              "        2.92371567e-05, 4.22638611e-05, 4.38312325e-03, 2.63029186e-05,\n",
              "        6.94885418e-05, 5.86942575e-05, 4.06402354e-05, 2.43329960e-05,\n",
              "        8.93944922e-05, 2.83905977e-05, 1.88637165e-05, 2.32043846e-04,\n",
              "        1.71882434e-05, 2.32847938e-05, 1.81650263e-04, 2.35566243e-05,\n",
              "        1.71114793e-05, 4.80831582e-05, 3.95650155e-05, 2.22799783e-04,\n",
              "        1.38257320e-04, 3.41814091e-05, 4.64877347e-05, 8.86960182e-05,\n",
              "        1.48146790e-05, 2.61748421e-05, 1.59237911e-05, 4.68273998e-05,\n",
              "        1.00208531e-03, 2.31713423e-05, 3.81508468e-05, 1.34205731e-05,\n",
              "        1.80402061e-05, 2.18698336e-05, 4.76669282e-05, 5.66334416e-05,\n",
              "        1.76433615e-05, 1.26249822e-04, 2.42421873e-05, 3.38610121e-05,\n",
              "        1.10574825e-05, 3.63702053e-05, 2.14250720e-04, 7.90961173e-05,\n",
              "        1.26638200e-04, 2.14666772e-05, 1.88781752e-05, 3.59009300e-05,\n",
              "        2.35961633e-04, 4.12877102e-05, 2.19922756e-05, 2.58644492e-05,\n",
              "        1.75248561e-04, 1.87213094e-05, 2.67170970e-05, 1.56406324e-04,\n",
              "        1.64289287e-04, 2.18969293e-04, 1.17193342e-05, 2.00909779e-05,\n",
              "        8.38865666e-05, 2.14901784e-05, 2.65330637e-05, 2.53890600e-05,\n",
              "        1.30381615e-05, 1.98967411e-05, 2.05990639e-04, 1.83424324e-05,\n",
              "        2.88542041e-05, 1.05325827e-04, 2.09127753e-05, 2.55054843e-05,\n",
              "        1.37453222e-05, 1.48176593e-04, 2.64801374e-05, 9.44247865e-05,\n",
              "        1.45676678e-05, 3.10243315e-05, 3.86521742e-05, 1.03062525e-04,\n",
              "        9.03638497e-05, 4.69413670e-05, 2.80427969e-04, 1.97814560e-04,\n",
              "        3.08169640e-05, 4.01944593e-05, 2.39726798e-04, 1.83266827e-05,\n",
              "        2.06386227e-05, 2.53565305e-05, 3.45326905e-05, 1.31658876e-05,\n",
              "        4.56077729e-05, 1.81476480e-05, 3.56953303e-05, 8.48575492e-04,\n",
              "        6.19301852e-03, 1.26874531e-05, 5.53873403e-05, 7.17557383e-05,\n",
              "        6.36298050e-05, 4.19554381e-05, 3.32664923e-05, 2.70505816e-05,\n",
              "        8.18861999e-05, 7.72981420e-05, 1.87662085e-04, 1.45387642e-05,\n",
              "        2.48273315e-05, 4.05293072e-05, 5.85550206e-05, 2.35409613e-04,\n",
              "        1.55383079e-05, 2.37084471e-05, 1.65068944e-04, 3.14607747e-05,\n",
              "        8.11073795e-05, 4.84573078e-05, 2.33039252e-05, 2.39489060e-05,\n",
              "        1.18574416e-04, 4.27812495e-05, 8.64511160e-05, 3.00511842e-05,\n",
              "        2.76822760e-05, 2.80971617e-05, 2.39690032e-04, 3.26813732e-04,\n",
              "        1.75797748e-04, 2.57952931e-04, 3.13552249e-05, 1.47567303e-04,\n",
              "        1.87640117e-05, 7.87735851e-05, 1.52543181e-05, 5.69139457e-05,\n",
              "        4.95675380e-05, 1.40088768e-04, 5.93173753e-04, 4.17554186e-05,\n",
              "        1.64233724e-04, 1.57838502e-04, 3.39213924e-05, 3.08623066e-05,\n",
              "        2.41448227e-05, 4.42100311e-05, 1.65740571e-04, 2.14200219e-05,\n",
              "        1.95588117e-05, 3.25470616e-05, 1.48985128e-04, 1.74000486e-05,\n",
              "        1.77698471e-05, 1.05019917e-04, 3.21049894e-05, 1.62875429e-04,\n",
              "        8.32774766e-05, 1.75672569e-04, 2.01164842e-04, 2.48596783e-04,\n",
              "        5.99083601e-05, 2.80704441e-05, 3.07045366e-05, 2.07121947e-05,\n",
              "        1.88089963e-04, 2.67783376e-04, 3.90494407e-05, 2.76287062e-04,\n",
              "        2.42837955e-05, 2.17695878e-05, 3.02923354e-05, 5.22484676e-04]),\n",
              " 'std_test_score': array([0.09609952, 0.02793075, 0.0638154 , 0.09609952, 0.07821511,\n",
              "        0.080762  , 0.09609952, 0.08436589, 0.08025908, 0.09168282,\n",
              "        0.05456984, 0.06867384, 0.09609952, 0.07307411, 0.080762  ,\n",
              "        0.09609952, 0.07054866, 0.07696267, 0.09609952, 0.06525984,\n",
              "        0.09147512, 0.09168282, 0.08073634, 0.0841737 , 0.09609952,\n",
              "        0.07911287, 0.08478895, 0.09609952, 0.07377687, 0.09856644,\n",
              "        0.09609952, 0.07326457, 0.08804475, 0.09168282, 0.08457769,\n",
              "        0.09469395, 0.09168282, 0.06323435, 0.0956241 , 0.09168282,\n",
              "        0.09571072, 0.10127481, 0.09609952, 0.0840976 , 0.09961553,\n",
              "        0.0925293 , 0.00647281, 0.03603324, 0.04411181, 0.00647281,\n",
              "        0.06862172, 0.07370216, 0.00647281, 0.07022224, 0.05751357,\n",
              "        0.00647281, 0.07336732, 0.08851566, 0.00647281, 0.09167049,\n",
              "        0.02732408, 0.00647281, 0.089878  , 0.07113284, 0.00647281,\n",
              "        0.07224471, 0.05596016, 0.00647281, 0.08737054, 0.07317455,\n",
              "        0.00647281, 0.0956241 , 0.044115  , 0.00647281, 0.04263999,\n",
              "        0.07445213, 0.00647281, 0.08242839, 0.07074146, 0.00647281,\n",
              "        0.04263999, 0.05212611, 0.00647281, 0.08971862, 0.07632319,\n",
              "        0.00647281, 0.09570678, 0.05622204, 0.00647281, 0.09943577,\n",
              "        0.04950313, 0.00749733, 0.07336732, 0.04975262, 0.07792564,\n",
              "        0.07815489, 0.06299863, 0.07750156, 0.08094833, 0.06186748,\n",
              "        0.04174732, 0.09094448, 0.05934748, 0.06676895, 0.09570678,\n",
              "        0.07138985, 0.07575667, 0.10042516, 0.10080138, 0.05450423,\n",
              "        0.09114513, 0.05809673, 0.06922013, 0.08139841, 0.03904335,\n",
              "        0.07438192, 0.09367419, 0.07534537, 0.06475286, 0.08614847,\n",
              "        0.06563391, 0.0798474 , 0.09725273, 0.04228518, 0.10201591,\n",
              "        0.08679529, 0.06359369, 0.07225514, 0.08548353, 0.06887921,\n",
              "        0.11504726, 0.10451437, 0.05249782, 0.09212339, 0.12039051,\n",
              "        0.06049911, 0.03803674, 0.07796188, 0.05877211, 0.06637574,\n",
              "        0.10053948, 0.10101414, 0.07227077, 0.07633615, 0.06560234,\n",
              "        0.02064166, 0.08696004, 0.05880794, 0.07153743, 0.08164098,\n",
              "        0.07427692, 0.06916842, 0.08889622, 0.05628814, 0.02378685,\n",
              "        0.07956387, 0.07381451, 0.06991045, 0.08455319, 0.07971697,\n",
              "        0.07873586, 0.07044715, 0.07205873, 0.02950462, 0.08713312,\n",
              "        0.07941401, 0.10635413, 0.09967412, 0.03680374, 0.10401948,\n",
              "        0.0839407 , 0.06211052, 0.06388914, 0.08189663, 0.03009078,\n",
              "        0.07178708, 0.09758137, 0.08576011, 0.11010907, 0.07920029])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXf1r6RumL4e",
        "colab_type": "text"
      },
      "source": [
        "O Grid Search apesar de ter um resultado melhor não é tanto assim, e o tempo de execução é muito alto, podendo ser até inviável usar esse método"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53cOvaAHmpPN",
        "colab_type": "text"
      },
      "source": [
        "## Interpretação final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTpsuLu5mrmv",
        "colab_type": "text"
      },
      "source": [
        "O problema não foi bem resolvido com um classificador, isto pode se dar por diversos motivos, porém os mais prováveis são: \n",
        "* 1)O dataset é pequeno e com poucas diferenças tornando difícil a identificação das características que diferem os casos. E também com diferenças significativas entre a quantidade de ocorrências de uma classe e de outra.\n",
        "* 2) Este problema pode ter influência externa que não está sendo colocada em nenhum dos atributos presentes, tornando assim impossível a análise do resultado levando em conta esses fatores.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Para melhorar isso seria necessário melhorar o dataset e refazer todos os passos para verificar se a mudança seria o suficiente para ajudar no classificador."
      ]
    }
  ]
}